{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Variants\n",
    "Variant 1: Random Subset of Features \n",
    "\n",
    "Variant 2: Relaxing the Upper and Lower Bound Difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 334\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# run when executed directly ---------------------------------------------------\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 334\u001b[0m     \u001b[43mrun_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 307\u001b[0m, in \u001b[0;36mrun_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    297\u001b[0m clf \u001b[38;5;241m=\u001b[39m GOSDTScratch(\n\u001b[1;32m    298\u001b[0m     lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m    299\u001b[0m     depth_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    305\u001b[0m )\n\u001b[1;32m    306\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train_bin, y_train)\n\u001b[0;32m--> 307\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_bin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m runtime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    309\u001b[0m acc \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m y_test)\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[8], line 148\u001b[0m, in \u001b[0;36mGOSDTScratch.predict\u001b[0;34m(self, X_bin)\u001b[0m\n\u001b[1;32m    146\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(X_bin\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out)):\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_row(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, X_bin[i])\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "gosdt_scratch.py\n",
    "\n",
    "Pure‑Python (NumPy‑only) re‑implementation of the GOSDT algorithm\n",
    "with two optional efficiency tweaks:\n",
    "\n",
    "    * random feature subset per split         (use_feature_subsample = True)\n",
    "    * relaxed hierarchical/pruning bound      (relax_bound           = True)\n",
    "\n",
    "Written from the descriptions in:\n",
    "  – Lin et al.,  ICML’20  paper\n",
    "  – Rudin course notes (Modern Decision‑Tree Optimisation)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Utility: binarise data (exact mid‑point‑split encoding)\n",
    "def binarise(X_orig, thresholds=None):\n",
    "    \"\"\"\n",
    "    Turn a real‑valued matrix (n × p) into binary indicators x ≤ θ.\n",
    "\n",
    "    Returns X_bin (n × m) and a list ‘meta’ with (orig_col, θ) pairs.\n",
    "    If ‘thresholds’ is passed, we re‑use those (enables test split).\n",
    "    \"\"\"\n",
    "    n, p = X_orig.shape\n",
    "    if thresholds is None:                         # build once from training data\n",
    "        thresholds = []\n",
    "        for j in range(p):\n",
    "            uniq = np.unique(X_orig[:, j])\n",
    "            if len(uniq) == 1:                     # constant → skip\n",
    "                continue\n",
    "            mids = (uniq[:-1] + uniq[1:]) / 2.0\n",
    "            thresholds.extend((j, float(t)) for t in mids)\n",
    "\n",
    "    # build binary design\n",
    "    X_bin = np.empty((n, len(thresholds)), dtype=np.uint8)\n",
    "    for k, (j, t) in enumerate(thresholds):\n",
    "        X_bin[:, k] = (X_orig[:, j] <= t).astype(np.uint8)\n",
    "\n",
    "    return X_bin, thresholds\n",
    "\n",
    "#  Node object for the search tree\n",
    "class Node:\n",
    "    __slots__ = (\n",
    "        \"bitmask\", \"depth\", \"pred\", \"lb\", \"ub\",\n",
    "        \"left\", \"right\", \"split_feature\",\n",
    "    )\n",
    "\n",
    "    def __init__(self, bitmask, depth):\n",
    "        self.bitmask = bitmask            # frozenset of row indices\n",
    "        self.depth   = depth\n",
    "        self.pred    = None               # majority label (set when leaf)\n",
    "        self.lb = 0.0                     # lower bound on objective\n",
    "        self.ub = math.inf                # upper bound on objective\n",
    "        self.left = self.right = None\n",
    "        self.split_feature = None\n",
    "\n",
    "    # leaf test\n",
    "    def is_leaf(self):\n",
    "        return self.left is None and self.right is None\n",
    "\n",
    "\n",
    "\n",
    "class GOSDTScratch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lam=0.02,\n",
    "        depth_limit=5,\n",
    "        use_feature_subsample=False,\n",
    "        feat_rate=0.5,\n",
    "        relax_bound=False,\n",
    "        eps=0.01,\n",
    "        random_state=0,\n",
    "    ):\n",
    "        self.lam = lam\n",
    "        self.D   = depth_limit\n",
    "        self.use_feature_subsample = use_feature_subsample\n",
    "        self.feat_rate = feat_rate\n",
    "        self.relax_bound = relax_bound\n",
    "        self.eps = eps\n",
    "        self.rng = random.Random(random_state)\n",
    "\n",
    "        # attributes filled after fit()\n",
    "        self.root       = None\n",
    "        self.n_features = None\n",
    "        self.y          = None\n",
    "\n",
    "\n",
    "    # public API\n",
    "    def fit(self, X_bin, y):\n",
    "        \"\"\"X_bin must be binary 0/1 matrix (already binarised).\"\"\"\n",
    "        n, m = X_bin.shape\n",
    "        self.n_features = m\n",
    "        self.y = y\n",
    "\n",
    "        # pre‑compute indices of positives / negatives per column\n",
    "        self.col_pos = [set(np.nonzero(X_bin[:, j])[0]) for j in range(m)]\n",
    "        self.col_neg = [set(range(n)) - col for col in self.col_pos]\n",
    "\n",
    "        # global best\n",
    "        self.best_obj = math.inf\n",
    "        self.best_tree = None\n",
    "\n",
    "        # memoisation: map bitmask → (lb, ub)  (dynamic programming reuse)\n",
    "        self.memo = {}\n",
    "\n",
    "        # priority queue (deque works: process shallow nodes first)\n",
    "        master_set = frozenset(range(n))\n",
    "        self.root = Node(master_set, depth=0)\n",
    "        self._init_bounds(self.root)\n",
    "\n",
    "        Q = deque([self.root])\n",
    "        while Q:\n",
    "            node = Q.popleft()\n",
    "\n",
    "            # bound + prune\n",
    "            if node.lb >= self.best_obj:\n",
    "                continue\n",
    "\n",
    "            # solve sub‑problem (branch or leaf)\n",
    "            solved = self._process_node(node)\n",
    "            if solved:\n",
    "                if node.ub < self.best_obj:\n",
    "                    self.best_obj = node.ub\n",
    "                    self.best_tree = node\n",
    "            else:\n",
    "                # push viable children in BFS order\n",
    "                if node.left.lb < self.best_obj:\n",
    "                    Q.append(node.left)\n",
    "                if node.right.lb < self.best_obj:\n",
    "                    Q.append(node.right)\n",
    "\n",
    "        # store final root (best_tree is a pointer inside that structure)\n",
    "        self.root = self.best_tree\n",
    "\n",
    "    def predict(self, X_bin):\n",
    "        out = np.empty(X_bin.shape[0], dtype=int)\n",
    "        for i in range(len(out)):\n",
    "            out[i] = self._predict_row(self.root, X_bin[i])\n",
    "        return out\n",
    "\n",
    "\n",
    "    # helpers\n",
    "\n",
    "    def _predict_row(self, node, x_row):\n",
    "        while not node.is_leaf():\n",
    "            node = node.left if x_row[node.split_feature] else node.right\n",
    "        return node.pred\n",
    "\n",
    "    # --------------------  bounds initialisation  --------------------\n",
    "    def _init_bounds(self, node):\n",
    "        \"\"\"Compute trivial leaf objective for upper bound; lower bound = 0.\"\"\"\n",
    "        idx = list(node.bitmask)\n",
    "        if not idx:                       # empty set (shouldn't happen)\n",
    "            node.lb = node.ub = 0.0\n",
    "            return\n",
    "\n",
    "        y_sub = self.y[idx]\n",
    "        pos = np.count_nonzero(y_sub)\n",
    "        neg = len(idx) - pos\n",
    "        minority = min(pos, neg)\n",
    "\n",
    "        node.pred = 1 if pos >= neg else 0\n",
    "        loss_leaf = minority / len(self.y)            # global normalisation\n",
    "        node.lb = 0.0                                # best possible loss after splits\n",
    "        node.ub = loss_leaf + self.lam               # make‑it‑leaf objective\n",
    "\n",
    "        # relaxed bound tweak: enlarge lb to prune more aggressively\n",
    "        if self.relax_bound:\n",
    "            node.lb += self.eps\n",
    "\n",
    "        self.memo[node.bitmask] = (node.lb, node.ub)\n",
    "\n",
    "    # --------------------  branch‑and‑bound step  --------------------\n",
    "    def _process_node(self, node):\n",
    "        \"\"\"\n",
    "        Returns True if node is final (leaf),\n",
    "        False if it was split and children inserted.\n",
    "        \"\"\"\n",
    "        # trivial cases\n",
    "        if node.depth >= self.D:\n",
    "            node.lb = node.ub                         # cannot split further\n",
    "            return True\n",
    "        if node.ub - node.lb <= 1e-12:                # perfect or pruned\n",
    "            return True\n",
    "\n",
    "        best_feature = None\n",
    "        best_l, best_r = None, None\n",
    "        best_obj = math.inf\n",
    "\n",
    "        # candidate feature set ---------------------------------------\n",
    "        feat_indices = range(self.n_features)\n",
    "        if self.use_feature_subsample:\n",
    "            k = max(1, int(self.feat_rate * self.n_features))\n",
    "            feat_indices = self.rng.sample(list(feat_indices), k)\n",
    "\n",
    "        for j in feat_indices:\n",
    "            left_set  = node.bitmask & self.col_pos[j]\n",
    "            right_set = node.bitmask & self.col_neg[j]\n",
    "            if not left_set or not right_set:         # useless split\n",
    "                continue\n",
    "\n",
    "            # reuse children bounds if already solved\n",
    "            l_lb, l_ub = self.memo.get(left_set, (None, None))\n",
    "            r_lb, r_ub = self.memo.get(right_set, (None, None))\n",
    "\n",
    "            # child not seen → create temp Node for bounds\n",
    "            if l_lb is None:\n",
    "                l_temp = Node(left_set, node.depth + 1)\n",
    "                self._init_bounds(l_temp)\n",
    "                l_lb, l_ub = l_temp.lb, l_temp.ub\n",
    "            if r_lb is None:\n",
    "                r_temp = Node(right_set, node.depth + 1)\n",
    "                self._init_bounds(r_temp)\n",
    "                r_lb, r_ub = r_temp.lb, r_temp.ub\n",
    "\n",
    "            lb_split = l_lb + r_lb\n",
    "            ub_split = l_ub + r_ub\n",
    "\n",
    "            if ub_split < best_obj:\n",
    "                best_obj = ub_split\n",
    "                best_feature = j\n",
    "                best_l, best_r = (left_set, (l_lb, l_ub)), (right_set, (r_lb, r_ub))\n",
    "\n",
    "        # no admissible split improves upper bound ⇒ keep as leaf\n",
    "        if best_feature is None or best_obj >= node.ub - 1e-12:\n",
    "            node.lb = node.ub\n",
    "            return True\n",
    "\n",
    "        # materialise children nodes\n",
    "        l_set, (l_lb, l_ub) = best_l\n",
    "        r_set, (r_lb, r_ub) = best_r\n",
    "        node.split_feature = best_feature\n",
    "\n",
    "        node.left  = Node(l_set, node.depth + 1)\n",
    "        node.right = Node(r_set, node.depth + 1)\n",
    "        node.left.lb,  node.left.ub  = l_lb, l_ub\n",
    "        node.right.lb, node.right.ub = r_lb, r_ub\n",
    "\n",
    "        # update current bounds\n",
    "        node.lb = node.left.lb + node.right.lb + self.lam   # +λ for this split\n",
    "        node.ub = node.left.ub + node.right.ub + self.lam\n",
    "\n",
    "        # write in memo\n",
    "        self.memo[node.bitmask] = (node.lb, node.ub)\n",
    "        return False\n",
    "\n",
    "\n",
    "#  Demo on 50‑sample Wine subset, four scenarios\n",
    "\n",
    "def run_demo():\n",
    "    # raw wine data (from UCI): embed CSV to stay std‑lib, or generate quickly\n",
    "    import urllib.request, io, csv\n",
    "    URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "    with urllib.request.urlopen(URL) as resp:\n",
    "        data = np.loadtxt(io.BytesIO(resp.read()), delimiter=\",\")\n",
    "    y_raw  = data[:, 0].astype(int) - 1                # classes 0,1,2\n",
    "    X_raw  = data[:, 1:]\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "    idx = rng.choice(len(X_raw), 50, replace=False)\n",
    "    X_raw, y_raw = X_raw[idx], y_raw[idx]\n",
    "\n",
    "    # 70 / 30 split\n",
    "    n = len(X_raw)\n",
    "    perm = rng.permutation(n)\n",
    "    train_idx = perm[: int(0.7 * n)]\n",
    "    test_idx  = perm[int(0.7 * n):]\n",
    "\n",
    "    X_train_raw, y_train = X_raw[train_idx], y_raw[train_idx]\n",
    "    X_test_raw,  y_test  = X_raw[test_idx],  y_raw[test_idx]\n",
    "\n",
    "    # binarise with thresholds learned on training part\n",
    "    X_train_bin, thresholds = binarise(X_train_raw)\n",
    "    X_test_bin, _           = binarise(X_test_raw, thresholds)\n",
    "\n",
    "    configs = [\n",
    "        dict(name=\"Baseline\",          subsample=False, relax=False),\n",
    "        dict(name=\"Random subset\",     subsample=True,  relax=False),\n",
    "        dict(name=\"Relaxed bound\",     subsample=False, relax=True),\n",
    "        dict(name=\"Both\",              subsample=True,  relax=True),\n",
    "    ]\n",
    "\n",
    "    accs, times = [], []\n",
    "    for cfg in configs:\n",
    "        t0 = time.perf_counter()\n",
    "        clf = GOSDTScratch(\n",
    "            lam=0.02,\n",
    "            depth_limit=5,\n",
    "            use_feature_subsample=cfg[\"subsample\"],\n",
    "            feat_rate=0.5,\n",
    "            relax_bound=cfg[\"relax\"],\n",
    "            eps=0.01,\n",
    "            random_state=0,\n",
    "        )\n",
    "        clf.fit(X_train_bin, y_train)\n",
    "        preds = clf.predict(X_test_bin)\n",
    "        runtime = time.perf_counter() - t0\n",
    "        acc = (preds == y_test).mean()\n",
    "        accs.append(acc)\n",
    "        times.append(runtime)\n",
    "        print(f\"{cfg['name']:>14s}  acc={acc:.2f}  time={runtime*1000:.1f} ms\")\n",
    "\n",
    "    # chart\n",
    "    xs = np.arange(len(configs))\n",
    "    width = 0.35\n",
    "    fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.bar(xs - width/2, accs, width, label=\"Accuracy\")\n",
    "    ax2.bar(xs + width/2, times, width, color=\"orange\", label=\"Runtime (s)\")\n",
    "    ax1.set_xticks(xs)\n",
    "    ax1.set_xticklabels([c[\"name\"] for c in configs])\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_ylabel(\"Seconds\")\n",
    "    ax1.set_title(\"Scratch‑built GOSDT variants on 50‑sample wine subset (λ = 0.02)\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# run when executed directly ---------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_x86-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
